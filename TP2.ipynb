{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e777fae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=10000,suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb19700c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "275a095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded df shape: (5000, 41)\n",
      "Columns preview (first 5 cols):\n",
      "     X0    X1    X2    X3    X4\n",
      "0 -0.23 -1.21  1.20  1.23 -0.10\n",
      "1  0.38  0.38 -0.31 -0.09  1.52\n",
      "2 -0.69  1.00  1.08  1.48  2.44\n",
      "3  0.40  0.68  0.27  1.39  1.03\n",
      "4 -0.81  1.59 -0.69  1.16  4.22\n",
      "label column name: label\n",
      "dtype: int64\n",
      "shape df: (5000, 41)\n",
      "n unique labels: 3\n",
      "value counts (sorted):\n",
      " label\n",
      "0    1692\n",
      "1    1653\n",
      "2    1655\n",
      "Name: count, dtype: int64\n",
      "Classe counts:\n",
      " label\n",
      "0    1692\n",
      "2    1655\n",
      "1    1653\n",
      "Name: count, dtype: int64\n",
      "A shape: (2500, 41), T shape: (2500, 41)\n"
     ]
    }
   ],
   "source": [
    "# Lire correctement le fichier Wave.txt en utilisant un séparateur d'espaces\n",
    "# (le fichier contient des valeurs séparées par des espaces, pas par des tabulations)\n",
    "# Utiliser sep='\\s+' pour gérer tout nombre d'espaces like '  ' ou '\\t'\n",
    "\n",
    "df = pd.read_csv('Wave.txt', sep='\\s+', header=None, engine='python')\n",
    "print(\"Loaded df shape:\", df.shape)\n",
    "\n",
    "# Renommer la dernière colonne en 'label' pour clarifier les diagnostics\n",
    "n_cols = df.shape[1]\n",
    "feature_names = [f'X{i}' for i in range(n_cols - 1)] + ['label']\n",
    "df.columns = feature_names\n",
    "\n",
    "print(\"Columns preview (first 5 cols):\")\n",
    "print(df.iloc[:, :5].head())\n",
    "\n",
    "# Vérification des labels\n",
    "y = df['label']\n",
    "print(\"label column name:\", y.name)\n",
    "print(\"dtype:\", y.dtype)\n",
    "print(\"shape df:\", df.shape)\n",
    "print(\"n unique labels:\", y.nunique())\n",
    "print(\"value counts (sorted):\\n\", y.value_counts().sort_index())\n",
    "\n",
    "# Créer un programme qui permet de découper votre base de données X avec un échantillonnage stratifié\n",
    "# par rapport aux labels en deux sous-ensembles d’apprentissage A et de test T de tailles respectivement\n",
    "# 1/2 et 1/2. La fonction gère les classes rares (moins de 2 échantillons) en revenant à un split aléatoire.\n",
    "\n",
    "def stratified_split(df, test_size=0.5, random_state=42, min_count_for_stratify=2):\n",
    "    \"\"\"Retourne A (train) et T (test). Si certaines classes ont moins de\n",
    "    `min_count_for_stratify` échantillons, on utilisera un split aléatoire (pas de stratification).\n",
    "    \"\"\"\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    counts = y.value_counts()\n",
    "    # Afficher les comptes par classe pour aide au débogage\n",
    "    print(\"Classe counts:\\n\", counts)\n",
    "\n",
    "    if counts.min() < min_count_for_stratify:\n",
    "        rare = counts[counts < min_count_for_stratify]\n",
    "        print(f\"⚠️ Certaines classes sont trop rares ({len(rare)} classes), p.ex. :\\n{rare}\\n\"\n",
    "              \"Utilisation d'un split aléatoire (stratify=None).\")\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, stratify=None, random_state=random_state\n",
    "        )\n",
    "    else:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "        )\n",
    "\n",
    "    # Combiner les ensembles d'apprentissage et de test\n",
    "    A = pd.concat([X_train, y_train], axis=1)\n",
    "    T = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "    print(f\"A shape: {A.shape}, T shape: {T.shape}\")\n",
    "    return A, T\n",
    "\n",
    "\n",
    "A, T = stratified_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "257e1f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base A  partiellement etiquetée  pct (% des donnees labellisee par rapport a la taille totale de A )\n",
    "\n",
    "def semi_label(A, pct=0.1, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    A_labeled = A.copy()\n",
    "    n_samples = A.shape[0]\n",
    "    n_labeled = int(n_samples * pct)\n",
    "\n",
    "    # Sélectionner aléatoirement les indices des échantillons à étiqueter\n",
    "    labeled_indices = np.random.choice(n_samples, n_labeled, replace=False)\n",
    "\n",
    "    # Mettre les labels non sélectionnés à NaN\n",
    "    A_labeled.loc[~A_labeled.index.isin(labeled_indices), 'label'] = np.nan\n",
    "\n",
    "    print(f\"Nombre d'échantillons dans A: {n_samples}\")\n",
    "    print(f\"Nombre d'échantillons étiquetés dans A: {n_labeled}\")\n",
    "\n",
    "    # separation A_etiq  et a_non_etiq\n",
    "    A_etiq = A_labeled.dropna(subset=['label'])\n",
    "    A_non_etiq = A_labeled[A_labeled['label'].isna()]\n",
    "\n",
    "    return A_etiq, A_non_etiq\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5d77cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre d'échantillons dans A: 2500\n",
      "Nombre d'échantillons étiquetés dans A: 250\n",
      "        X0    X1    X2    X3    X4    X5    X6    X7    X8    X9  ...   X31  \\\n",
      "1011  1.26  0.79  0.28  3.12  1.37  6.73  5.07  5.35  2.99  3.59  ... -3.00   \n",
      "1977  0.78  1.36  2.06  1.68  0.91  2.44  1.49  3.39  0.77  2.25  ... -0.80   \n",
      "2054 -0.65  0.41  0.05  1.26  0.38 -0.87 -0.45  0.98  0.25  1.29  ... -0.86   \n",
      "756   0.15 -0.11  1.21 -1.41  1.36  0.90  3.14  2.35  3.88  6.66  ...  1.09   \n",
      "450  -0.84 -0.83  2.19  2.11  3.53  4.13  5.51  4.63  4.18  4.38  ... -1.00   \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
      "1047  0.47 -1.03  1.24  0.49  0.16  2.06  2.87  2.14  0.52  0.39  ...  0.04   \n",
      "2442  0.82 -0.31  1.92  0.65  1.12  0.85 -0.07  2.19  1.39  0.12  ...  0.15   \n",
      "1655  0.55 -2.33  2.36  3.10  0.95  2.49  3.48  4.24  4.58  5.20  ...  0.18   \n",
      "2032  1.68  1.06  0.44  3.66  2.08  1.62  3.60  3.46  3.72 -0.57  ...  0.70   \n",
      "2045 -0.70 -0.83  1.29  0.39 -0.77  1.82  0.91  2.79  2.70  5.64  ...  0.79   \n",
      "\n",
      "       X32   X33   X34   X35   X36   X37   X38   X39  label  \n",
      "1011 -0.84 -1.08 -0.47 -1.44 -0.21  0.79  0.37  2.27    1.0  \n",
      "1977 -0.42  0.16  1.17 -0.34 -0.56  0.43  0.36  0.54    0.0  \n",
      "2054  0.13 -0.05  0.57 -0.52  0.17  1.47  0.07  0.90    2.0  \n",
      "756   0.12 -1.80  1.63  0.66 -1.18 -0.52  0.34 -0.33    1.0  \n",
      "450  -1.46 -0.44  0.03  0.07 -0.36  1.94 -0.84 -0.35    1.0  \n",
      "...    ...   ...   ...   ...   ...   ...   ...   ...    ...  \n",
      "1047  0.63  0.63 -0.22 -0.08 -0.91 -0.19  0.48 -0.16    0.0  \n",
      "2442 -1.19  0.35 -1.08  0.19 -0.64  0.90  0.10  2.31    0.0  \n",
      "1655 -0.20  1.10 -0.54  0.92  0.39 -0.47  0.13 -0.31    1.0  \n",
      "2032  0.71 -0.27 -0.03 -0.48  0.21 -1.09 -0.13  0.38    0.0  \n",
      "2045 -0.39  0.20 -1.35 -0.05 -2.08 -0.38  0.97  0.38    1.0  \n",
      "\n",
      "[135 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "A_labeled = semi_label(A, pct=0.1)\n",
    "A_etiq = A_labeled[0]\n",
    "print(A_etiq)\n",
    "A_non_etiq = A_labeled[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44766252",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: placeholder S1 removed — Fisher-score calculation is implemented in the next cell\n",
    "# This cell kept for informational purpose only.\n",
    "# Original S1(v) was incorrect; the correct calculations use S1 (between-class) and S2 (within-class)\n",
    "# computed only on the labeled samples of A_labeled.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fcdb93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# S1(v) = sum_k n_k * (mu_k - mu)^2 / sum_k n_k * sigma (ecart type) ²\n",
    "# S2(v) = sum_k n_k * sigma_k^2\n",
    "\n",
    "def S1(x, y):\n",
    "    mu = x.mean()\n",
    "    s1 = 0.0\n",
    "    s2 = 0.0\n",
    "    for k, group in x.groupby(y):\n",
    "        n_k = len(group)\n",
    "        mu_k = group.mean()\n",
    "        s1 += n_k * (mu_k - mu) ** 2\n",
    "        var_k = group.var(ddof=0)\n",
    "        s2 += n_k * var_k\n",
    "    return s1 / s2 if s2 != 0 else np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92f78ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S2(x, t=10):\n",
    "    x = x.values  # vecteur numpy\n",
    "    var = np.var(x)\n",
    "    if var == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    n = len(x)\n",
    "    score = 0.0\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            S_ij = np.exp(- ((x[i] - x[j])**2) / t)\n",
    "            score += S_ij * ((x[i] - x[j])**2) / var\n",
    "    \n",
    "    return score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70114a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_scores(A_etiq, A_non_etiq):\n",
    "    \n",
    "    X_etiq = A_etiq.drop(columns=[\"label\"])\n",
    "    y = A_etiq[\"label\"]\n",
    "    X_non = A_non_etiq.drop(columns=[\"label\"])\n",
    "    \n",
    "    scores = {}\n",
    "    \n",
    "    for v in X_etiq.columns:\n",
    "        s1 = S1(X_etiq[v], y)\n",
    "        s2 = S2(X_non[v])\n",
    "        scores[v] = s1 / s2 if s2 not in [0, np.nan] else np.nan\n",
    "    \n",
    "    return pd.Series(scores).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec90a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = compute_scores(A_etiq, A_non_etiq)\n",
    "print(scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
