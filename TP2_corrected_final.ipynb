{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(threshold=10000, suppress=True)\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# TP2 - Sélection de variables semi-supervisée\n",
    "\n",
    "## Dataset: Wave.txt (vagues de Brieman)\n",
    "- 5000 individus\n",
    "- 40 variables  \n",
    "- 3 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part1_title",
   "metadata": {},
   "source": [
    "## I. Découpage de la base en apprentissage/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lecture du fichier Wave.txt\n",
    "df = pd.read_csv('C:\\\\Users\\\\hp\\\\OneDrive\\\\Documents\\\\POLYTECH\\\\2025_2026\\\\Big_data_tp1\\\\Wave.txt', sep='\\s+', header=None, engine='python')\n",
    "print(\"Loaded df shape:\", df.shape)\n",
    "\n",
    "# Renommer les colonnes\n",
    "n_cols = df.shape[1]\n",
    "feature_names = [f'X{i}' for i in range(n_cols - 1)] + ['label']\n",
    "df.columns = feature_names\n",
    "\n",
    "print(\"\\nAperçu des données:\")\n",
    "print(df.head())\n",
    "\n",
    "# Vérification des labels\n",
    "y = df['label']\n",
    "print(\"\\nInformations sur les labels:\")\n",
    "print(f\"  - Nombre de classes: {y.nunique()}\")\n",
    "print(f\"  - Distribution:\\n{y.value_counts().sort_index()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stratified_split",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(df, test_size=0.5, random_state=42):\n",
    "    \"\"\"Découpe stratifiée ET normalisation automatique.\"\"\"\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df.iloc[:, -1]\n",
    "\n",
    "    # Découpage\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Normalisation\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    A = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "    A['label'] = y_train.values\n",
    "    \n",
    "    T = pd.DataFrame(X_test_scaled, columns=X.columns)\n",
    "    T['label'] = y_test.values\n",
    "\n",
    "    print(\"Données normalisées avec succès (Moyenne=0, Écart-type=1)\")\n",
    "    return A, T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deac5e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "A , T = stratified_split(df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part2_title",
   "metadata": {},
   "source": [
    "## II. Simulation de l'aspect semi-supervisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "semi_label",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semi_label(A, pct=0.1, random_state=42):\n",
    "    np.random.seed(random_state)\n",
    "    A_copy = A.copy().reset_index(drop=True)\n",
    "    \n",
    "    # Identification des colonnes\n",
    "    y_col = A_copy.columns[-1]   # La colonne 'label'\n",
    "    \n",
    "    # Sélection des indices à étiqueter\n",
    "    n_samples = A_copy.shape[0]\n",
    "    n_labeled = int(n_samples * pct)\n",
    "    \n",
    "    indices = np.arange(n_samples)\n",
    "    labeled_indices = np.random.choice(indices, n_labeled, replace=False)\n",
    "    unlabeled_indices = np.setdiff1d(indices, labeled_indices)\n",
    "\n",
    "    # Création des deux sous-ensembles\n",
    "    A_etiq = A_copy.iloc[labeled_indices].copy()\n",
    "    A_non_etiq = A_copy.iloc[unlabeled_indices].copy()\n",
    "    \n",
    "    # On \"cache\" les labels de la partie non-étiquetée pour la simulation\n",
    "    A_non_etiq[y_col] = np.nan\n",
    "\n",
    "    print(f\"Simulation semi-supervisée prête (Données déjà normalisées).\")\n",
    "    print(f\" - Échantillons étiquetés: {len(A_etiq)}\")\n",
    "    print(f\" - Échantillons non étiquetés: {len(A_non_etiq)}\")\n",
    "    \n",
    "    return A_etiq, A_non_etiq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71832e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_etiq, A_non_etiq = semi_label(A, pct=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s1_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S1(x, y):\n",
    "    mu = x.mean()\n",
    "    between_var = 0.0\n",
    "    within_var = 0.0\n",
    "    \n",
    "    for label, group in x.groupby(y):\n",
    "        n_k = len(group)\n",
    "        mu_k = group.mean()\n",
    "        \n",
    "        sigma_k_sq = np.var(group) \n",
    "        \n",
    "        between_var += n_k * (mu_k - mu) ** 2\n",
    "        within_var += n_k * sigma_k_sq\n",
    " \n",
    "    \n",
    "    return between_var / within_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "s2_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "def S2(x, t=10):\n",
    "    x_arr = x.values.astype(float)\n",
    "    var = np.var(x_arr)\n",
    "    \n",
    "    if var == 0 or np.isnan(var):\n",
    "        return np.nan\n",
    "    \n",
    "    n = len(x_arr)\n",
    "    \n",
    "    diff_matrix = x_arr[:, None] - x_arr[None, :]  \n",
    "\n",
    "    S_matrix = np.exp(-(diff_matrix ** 2) / t)\n",
    "    \n",
    "    numerator = np.sum((diff_matrix ** 2) * S_matrix)\n",
    "    score = numerator / var\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compute_scores",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "def compute_scores(A_etiq, A_non_etiq, t=10):\n",
    "   \n",
    "    X_etiq = A_etiq.drop(columns=[\"label\"])\n",
    "    y = A_etiq[\"label\"]\n",
    "    X_non = A_non_etiq.drop(columns=[\"label\"])\n",
    "   \n",
    "    dist_sq = squareform(pdist(X_non, 'sqeuclidean'))\n",
    "    S_matrix = np.exp(-dist_sq / t)\n",
    "\n",
    "    scores = {}\n",
    "    s1_dict = {}\n",
    "    s2_dict = {}\n",
    "    \n",
    "    print(\"Calcul des scores pour chaque variable...\")\n",
    "    for i, v in enumerate(X_etiq.columns):\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"  Progression: {i + 1}/{len(X_etiq.columns)}\")\n",
    "        \n",
    "        # S1 (Fisher)\n",
    "        s1 = S1(X_etiq[v], y)\n",
    "        \n",
    "        # S2 (Laplace) \n",
    "        x_v = X_non[v].values\n",
    "        var_v = np.var(x_v)\n",
    "        \n",
    "        diff_v = (x_v[:, None] - x_v[None, :]) ** 2\n",
    "        numerator = np.sum(diff_v * S_matrix)\n",
    "        s2 = numerator / var_v\n",
    "        \n",
    "        s1_dict[v] = s1\n",
    "        s2_dict[v] = s2\n",
    "        \n",
    "        # Ratio final\n",
    "        if s2 > 0 and not np.isinf(s2):\n",
    "            scores[v] = s1 / s2\n",
    "        else:\n",
    "            scores[v] = 0.0\n",
    "            \n",
    "    return pd.Series(scores), s1_dict, s2_dict\n",
    "\n",
    "\n",
    "# On récupère bien les 3 dictionnaires renvoyés par la fonction\n",
    "scores, s1_results, s2_results = compute_scores(A_etiq, A_non_etiq, t=10)\n",
    "print(scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "part4_title",
   "metadata": {},
   "source": [
    "## IV. Évaluation de la sélection\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "histogram",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogramme des pertinences\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "scores_clean = scores.dropna()\n",
    "plt.bar(range(len(scores_clean)), scores_clean.values, color='steelblue', alpha=0.7)\n",
    "plt.xlabel('Variables (triées par score)', fontsize=11)\n",
    "plt.ylabel('Score S1/S2', fontsize=11)\n",
    "plt.title('Histogramme des pertinences de toutes les variables', fontweight='bold')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mlp_helper",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mlp(A_etiq, T, selected_vars, normalize=False, verbose=True):\n",
    "    \n",
    "    # Préparation des données\n",
    "    X_train = A_etiq[selected_vars]\n",
    "    y_train = A_etiq['label']\n",
    "    X_test = T[selected_vars]\n",
    "    y_test = T['label']\n",
    "    \n",
    "    \n",
    "    if normalize:\n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "    \n",
    "    # Entraînement du MLP\n",
    "    mlp = MLPClassifier(hidden_layer_sizes=(12, 10, 10), max_iter=5000, random_state=42)\n",
    "    \n",
    "    mlp.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédiction\n",
    "    y_pred = mlp.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"  Nombre de variables: {len(selected_vars)}\")\n",
    "        print(f\"  Normalisation: {'Oui' if normalize else 'Non'}\")\n",
    "        print(f\"  Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_normalization",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe d'efficacité avec/sans normalisation \n",
    "\n",
    "n_vars_range = list(range(5, 41, 5))  \n",
    "acc_no_norm = []\n",
    "acc_with_norm = []\n",
    "\n",
    "for n in n_vars_range:\n",
    "    selected = scores.head(n).index.tolist()\n",
    "    \n",
    "    print(f\"\\nTest avec {n} variables:\")\n",
    "    print(\"  Sans normalisation:\")\n",
    "    acc_nn = evaluate_mlp(A_etiq, T, selected, normalize=False)\n",
    "    acc_no_norm.append(acc_nn)\n",
    "    \n",
    "    print(\"  Avec normalisation:\")\n",
    "    acc_wn = evaluate_mlp(A_etiq, T, selected, normalize=True)\n",
    "    acc_with_norm.append(acc_wn)\n",
    "\n",
    "# Graphique\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_vars_range, acc_no_norm, 'o-', label='Sans normalisation', linewidth=2, markersize=8)\n",
    "plt.plot(n_vars_range, acc_with_norm, 's-', label='Avec normalisation', linewidth=2, markersize=8)\n",
    "plt.xlabel('Nombre de variables sélectionnées', fontsize=12)\n",
    "plt.ylabel('Accuracy sur T', fontsize=12)\n",
    "plt.title('Courbe d\\'efficacité du MLP (par tranches de 5 variables)', fontweight='bold', fontsize=13)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cac77b",
   "metadata": {},
   "source": [
    "La précision augmente de 49% à 80% entre 5 et 15 variables, ce qui prouve que le classement identifie les variables les plus riches en signal dès le début.\n",
    "Le pic de performance est atteint à 20 variables (83%). C'est le point d'équilibre où le modèle a assez d'informations sans être pollué par le bruit.\n",
    "Au-delà de 20 variables, l'accuracy chute ou stagne (78% à la fin), ce qui confirme que les variables à faible score sont inutiles, voire nuisibles.\n",
    "Avec seulement 5% de données étiquetées, on obtient déjà une précision de 83%, ce qui montre que la structure globale des données est capturée même avec très peu de labels.On constate également que la normalisation stabilise l'apprentissage et empêche l'effondrement de la précision quand le nombre de variables devient trop élevé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_pertinent_vars",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe sur variables non-pertinentes (normalisation activée)\n",
    "\n",
    "print(\"ÉVALUATION: VARIABLES NON-PERTINENTES\")\n",
    "\n",
    "scores_reversed = scores.sort_values(ascending=True)\n",
    "\n",
    "acc_non_pertinent = []\n",
    "for n in n_vars_range:\n",
    "    selected = scores_reversed.head(n).index.tolist()\n",
    "    \n",
    "    print(f\"\\nTest avec {n} variables NON-pertinentes:\")\n",
    "    acc = evaluate_mlp(A_etiq, T, selected, normalize=True)\n",
    "    acc_non_pertinent.append(acc)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_vars_range, acc_with_norm, 's-', label='Variables pertinentes (top)', \n",
    "         linewidth=2, markersize=8, color='forestgreen')\n",
    "plt.plot(n_vars_range, acc_non_pertinent, '^-', label='Variables non-pertinentes (bottom)', \n",
    "         linewidth=2, markersize=8, color='crimson')\n",
    "plt.xlabel('Nombre de variables sélectionnées', fontsize=12)\n",
    "plt.ylabel('Accuracy sur T', fontsize=12)\n",
    "plt.title('Comparaison: Variables pertinentes vs non-pertinentes (avec normalisation)', \n",
    "          fontweight='bold', fontsize=13)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa349c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation des données manquantes\n",
    "all_features = scores.index.tolist()\n",
    "\n",
    "# Courbe \"Sans sélection\" (constante sur l'axe X pour comparaison)\n",
    "acc_full_norm = evaluate_mlp(A_etiq, T, all_features, normalize=True, verbose=False)\n",
    "acc_full_no_norm = evaluate_mlp(A_etiq, T, all_features, normalize=False, verbose=False)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "# 1. Variables pertinentes (Normalisées)\n",
    "plt.plot(n_vars_range, acc_with_norm, 's-', label='Variables pertinentes (normalisées)', \n",
    "         color='tab:blue', linewidth=2, markersize=8)\n",
    "\n",
    "# 2. Variables pertinentes (Non normalisées)\n",
    "plt.plot(n_vars_range, acc_no_norm, 'o-', label='Variables pertinentes (non normalisées)', \n",
    "         color='tab:orange', linewidth=2, markersize=8)\n",
    "\n",
    "# 3. Variables NON-pertinentes (Normalisées)\n",
    "plt.plot(n_vars_range, acc_non_pertinent, '^-', label='Variables non-pertinentes', \n",
    "         color='tab:red', linewidth=2, markersize=8)\n",
    "\n",
    "# 4. Sans sélection de variables (Normalisées) \n",
    "plt.axhline(y=acc_full_norm, color='tab:blue', linestyle='--', alpha=0.6, \n",
    "            label=f'Sans sélection (norm) : {acc_full_norm:.4f}')\n",
    "\n",
    "# 5. Sans sélection de variables (Non normalisées)\n",
    "plt.axhline(y=acc_full_no_norm, color='tab:orange', linestyle='--', alpha=0.6, \n",
    "            label=f'Sans sélection (non-norm) : {acc_full_no_norm:.4f}')\n",
    "\n",
    "# Mise en forme\n",
    "plt.title(\"Courbes d'efficacité du MLP selon la sélection de variables\", fontweight='bold', fontsize=14)\n",
    "plt.xlabel(\"Nombre de variables sélectionnées\", fontsize=12)\n",
    "plt.ylabel(\"Précision (Accuracy) sur T\", fontsize=12)\n",
    "plt.legend(loc='lower right', fontsize=10)\n",
    "plt.grid(True, linestyle='-', alpha=0.3)\n",
    "plt.xticks(n_vars_range)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbe selon la sélection de variables (normalisation activée)\n",
    "print(\"ÉVALUATION: IMPACT DU NOMBRE DE VARIABLES\")\n",
    "\n",
    "\n",
    "# Test plus fin: de 1 à 40 variables\n",
    "n_vars_detailed = list(range(1, 41))\n",
    "acc_detailed = []\n",
    "\n",
    "for n in n_vars_detailed:\n",
    "    selected = scores.head(n).index.tolist()\n",
    "    acc = evaluate_mlp(A_etiq, T, selected, normalize=True, verbose=False)\n",
    "    acc_detailed.append(acc)\n",
    "    \n",
    "    if n % 10 == 0:\n",
    "        print(f\"  {n} variables: accuracy = {acc:.4f}\")\n",
    "\n",
    "# Graphique\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(n_vars_detailed, acc_detailed, 'o-', linewidth=2, markersize=5, color='steelblue')\n",
    "plt.axvline(x=20, color='red', linestyle='--', alpha=0.7, label='20 variables')\n",
    "plt.xlabel('Nombre de variables sélectionnées', fontsize=12)\n",
    "plt.ylabel('Accuracy sur T', fontsize=12)\n",
    "plt.title('Courbe de performance selon la sélection de variables (avec normalisation)', \n",
    "          fontweight='bold', fontsize=13)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Trouver le meilleur nombre de variables\n",
    "best_n = n_vars_detailed[np.argmax(acc_detailed)]\n",
    "best_acc = max(acc_detailed)\n",
    "print(f\"\\n Meilleur nombre de variables: {best_n} (accuracy = {best_acc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "test_labeling_pct",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impact du % de données labellisées (fixé à 20 variables)\n",
    "\n",
    "print(\"ÉVALUATION: IMPACT DU % DE DONNÉES LABELLISÉES\")\n",
    "\n",
    "\n",
    "pct_range = [0.05, 0.10, 0.15, 0.20, 0.30, 0.40, 0.50, 0.75, 1.0]\n",
    "acc_by_pct = []\n",
    "\n",
    "for pct in pct_range:\n",
    "    print(f\"\\nTest avec {pct*100:.0f}% de données labellisées:\")\n",
    "    \n",
    "    A_etiq_temp, A_non_etiq_temp = semi_label(A, pct=pct, random_state=42)\n",
    "    \n",
    "    scores_temp, _, _ = compute_scores(A_etiq_temp, A_non_etiq_temp, t=10)\n",
    "    \n",
    "    selected_20 = scores_temp.head(20).index.tolist()\n",
    "     \n",
    "    acc = evaluate_mlp(A_etiq_temp, T, selected_20, normalize=True)\n",
    "    acc_by_pct.append(acc)\n",
    "\n",
    "# Graphique\n",
    "plt.figure(figsize=(10, 6))\n",
    "pct_labels = [f\"{p*100:.0f}%\" for p in pct_range]\n",
    "plt.plot(pct_range, acc_by_pct, 'o-', linewidth=2, markersize=10, color='darkviolet')\n",
    "plt.xlabel('% de données labellisées dans A', fontsize=12)\n",
    "plt.ylabel('Accuracy sur T', fontsize=12)\n",
    "plt.title('Courbe de performance en fonction du % de données labellisées\\n(20 variables sélectionnées, avec normalisation)', \n",
    "          fontweight='bold', fontsize=13)\n",
    "plt.xticks(pct_range, pct_labels)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nMeilleur % de labellisation: {pct_range[np.argmax(acc_by_pct)]*100:.0f}% \"\n",
    "      f\"(accuracy = {max(acc_by_pct):.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101bb832",
   "metadata": {},
   "source": [
    "L'accuracy atteint son maximum lorsque le pourcentage de données labellisées est de 50% ainsi qu'à 100%. Cela montre que l'apprentissage semi-supervisé présente des avantages significatifs, pouvant même générer des résultats comparables à ceux obtenus avec 100% des données labellisées, c'est-à-dire dans un contexte d'apprentissage entièrement supervisé."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
